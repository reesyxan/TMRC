---
title: "TMRC3 ML Exploration"
author: "Theresa Alexander"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)


# load the package
library(VGAM)
library(openxlsx)
library(ggplot2)
library(stringr)
library(caTools)
library(scran)
library(scater)
library(gridExtra)
library(grid)
```

```{r}
normed_tmrc <- read.csv("~/Desktop/ElSayedLab/TMRC/tmrc_v202011.csv")
tmrc_metadata <- read.xlsx("~/Desktop/ElSayedLab/TMRC/TMRC_metadata.xlsx", rowNames = TRUE)

#subset to keep only samples with clinical outcome recorded
tmrc_clinicaloutcomesamples <- subset(tmrc_metadata, !is.na(clinicaloutcome) & clinicaloutcome != "lost")
normed_tmrc_clinicaloutcomes <- normed_tmrc[,tolower(rownames(tmrc_clinicaloutcomesamples))]
rownames(normed_tmrc_clinicaloutcomes) <- normed_tmrc$row.names

#subset first timepoint samples
timepoint <- str_sub(tmrc_clinicaloutcomesamples$samplename, -1)
#tmrc_firsttimepointsamples <- tmrc_clinicaloutcomesamples[str_sub(tmrc_clinicaloutcomesamples$samplename, -1) == 1,]

CellType <- tmrc_clinicaloutcomesamples$typeofcells

49 - m2

c("TMRC30026", "TMRC30049", "TMRC30055")
```

# PCA on all samples
```{r}
PCA_normedtmrc <- prcomp(normed_tmrc_clinicaloutcomes)

ggplot(as.data.frame(PCA_normedtmrc$rotation), aes(x = PC1, y = PC2, col = timepoint)) + 
  geom_point() +
  theme_classic() +
  geom_text(aes(label=rownames(PCA_normedtmrc$rotation)),hjust=0, vjust=0) +
  xlim(c(0.08, .32))

ggplot(as.data.frame(PCA_normedtmrc$rotation), aes(x = PC1, y = PC2, col = CellType)) + 
  geom_point() +
  theme_classic() +
  geom_text(aes(label=rownames(PCA_normedtmrc$rotation)),hjust=0, vjust=0) +
  xlim(c(0.08, .32))


```
Points don't offer a lot of variation based on timepoint, but do based on cell type. We'll take this non-separation by timepoint in the PCA as evidence that we can (for now) use all timepoints just to see what kind of predictive power we have with more samples.



# Split into Test and Train
```{r}
#create a list of random number ranging from 1 to number of rows from actual data and 70% of the data into training data  
set.seed(123)
train_indices <- sort(sample(nrow(t(normed_tmrc_clinicaloutcomes)), nrow(t(normed_tmrc_clinicaloutcomes))*.9))

#creating training data set by selecting the output row values
train <- t(normed_tmrc_clinicaloutcomes)[train_indices,]

#creating test data set by not selecting the output row values
test <- t(normed_tmrc_clinicaloutcomes)[-train_indices,]


target_train <- tmrc_clinicaloutcomesamples$clinicaloutcome[train_indices]
target_train_binary <- ifelse(target_train =="cure", 1, 0)
target_test <- tmrc_clinicaloutcomesamples$clinicaloutcome[-train_indices]
```

# Look at Highly Variable Genes of Training Data
```{r}
#subset highly variable genes
var_genes <- apply(t(train), 1, var)
select_var <- names(sort(var_genes, decreasing=TRUE))[1:500]
topvar <- head(select_var)

#stats <- scran::modelGeneVar(as.matrix(t(train)))
#var.features <- scran::getTopHVGs(stats, n = 10)

train_varfeatures <- train[,var.features]
celltype <- tmrc_clinicaloutcomesamples[train_indices,]$typeofcells
timepoint2 <- timepoint[train_indices]

boxplot(train_varfeatures[,1] ~ celltype)
boxplot(train_varfeatures[,2] ~ celltype)
boxplot(train_varfeatures[,3] ~ celltype)


boxplot(train_varfeatures[,1] ~ target_train)
boxplot(train_varfeatures[,2] ~ target_train)
boxplot(train_varfeatures[,3] ~ target_train)

```
As expected based on the PCA plot, all the HVG's give us are genes which are variable wrt cell type and not cure/fail, so these aren't going to help us predict outcome. We will do DE for the condition outcome to get a list of genes to use in the model.


# DE
```{r}
library(DESeq2)
#read in raw reads
rawreads <- read.xlsx("~/Desktop/ElSayedLab/TMRC/tmrc_rawreads.xlsx", rowNames = TRUE)
rawreads_train <- rawreads[,rownames(train)]



coldata <- data.frame(row.names = rownames(train), outcome = as.factor(target_train))


dds <- DESeqDataSetFromMatrix(countData = rawreads_train, 
                              colData = coldata, 
                              design = ~ outcome)

dds$outcome <- relevel(dds$outcome, ref = "failure")

dds <- dds[rownames(normed_tmrc_clinicaloutcomes),]

#filter lowly expressed genes 
keep <- rowSums(counts(dds)) >= 10
dds <- dds[keep,]

dds <- DESeq(dds)
res <- results(dds)
resOrdered <- res[order(res$pvalue),]

message(paste("There are ", sum(res$padj < 0.05 & res$log2FoldChange > 1, na.rm=TRUE), " genes with adjusted p-value < .05 and log2FC > 1"))
```


```{r}
res05 <- results(dds, alpha=0.05)

top25DEgenes_up <- rownames(res05[order(res05$log2FoldChange, decreasing = TRUE),][1:25,])
top25DEgenes_down <- rownames(res05[order(res05$log2FoldChange),][1:25,])
top50DEgenes_updown <- rownames(res05[order(abs(res05$log2FoldChange), decreasing = TRUE),][1:50,])

```

## Boxplots for top DE genes
```{r}
boxplot(train[,top50DEgenes_updown[1]] ~ target_train, ylab = top50DEgenes_updown[1], xlab = "")
boxplot(train[,top50DEgenes_updown[2]] ~ target_train, ylab = top50DEgenes_updown[2], xlab = "")
boxplot(train[,top50DEgenes_updown[3]] ~ target_train, ylab = top50DEgenes_updown[3], xlab = "")


boxplot(train[,top25DEgenes_up[1]] ~ target_train, ylab = top25DEgenes_up[1], xlab = "")
boxplot(train[,top25DEgenes_up[2]] ~ target_train, ylab = top25DEgenes_up[2], xlab = "")
boxplot(train[,top25DEgenes_up[3]] ~ target_train, ylab = top25DEgenes_up[3], xlab = "")

boxplot(train[,top25DEgenes_down[1]] ~ target_train, ylab = top25DEgenes_down[1], xlab = "")
boxplot(train[,top25DEgenes_down[2]] ~ target_train, ylab = top25DEgenes_down[2], xlab = "")
boxplot(train[,top25DEgenes_down[3]] ~ target_train, ylab = top25DEgenes_down[3], xlab = "")

message(paste("There are", sum(top25DEgenes_down %in% top50DEgenes_updown, 25-sum(top25DEgenes_up %in% top50DEgenes_updown)), "down regulated genes and", 50 - sum(top25DEgenes_down %in% top50DEgenes_updown, 25-sum(top25DEgenes_up %in% top50DEgenes_updown)), "upregulated genes in the top 50 DE genes."))

plot(train[,top25DEgenes_up[1]])
```

```{r, include=FALSEz}
writeLines("\nI am not sure why the top Positive FC genes have such outliers. This doesn't seem right to me so something to talk about on Wednesday. For now, I'll just use the top pos DE genes.")
```


# Logistic Regression Model
```{r}
#for the CV
library(boot)
library(nnet)
train_DEfeatures <- as.data.frame(train[,top25DEgenes_down[1:25]])

#make the models using multinom
fit_1var <- multinom(target_train_binary ~ train[,top25DEgenes_down[1]], data = data.frame(train[,top25DEgenes_down[1]]))
fit_2vars <- multinom(target_train_binary ~ train[,top25DEgenes_down[2]], data = data.frame(train[,top25DEgenes_down[2]]))
fit_3vars <- multinom(target_train_binary ~ train[,top25DEgenes_down[3]], data = data.frame(train[,top25DEgenes_down[3]]))

# summary of the models
summary(fit_1var)
summary(fit_2vars)
summary(fit_3vars)

exp(coef(fit_1var))
exp(coef(fit_2vars))
exp(coef(fit_3vars))
#get probabilities for prediction for each sample
probabilities_1var <- predict(fit_1var, as.data.frame(train_varfeatures)[,1:3], type = "response")
probabilities_2var <- predict(fit_2vars, as.data.frame(train_varfeatures)[,1:3], type="response")
probabilities_3var <- predict(fit_3vars, as.data.frame(train_varfeatures)[,1:3], type="response")

#turn probabilities into predictions
predictions_1var <- round(probabilities_1var) 
predictions_2var <- round(probabilities_2var) 
predictions_3var <- round(probabilities_3var) 


qplot(train_DEfeatures[,1], jitter(round(predictions_1var)), col=target_train, xlab = colnames(train_DEfeatures)[1], ylab = 'Prediction using Logistic Reg.')
plot(fit_1var)

qplot(train_DEfeatures[,1], jitter(round(predictions_2var)), col=target_train, xlab = colnames(train_DEfeatures)[2], ylab = 'Prediction using Logistic Reg.')

qplot(train_DEfeatures[,1], jitter(round(predictions_3var)), col=target_train, xlab = colnames(train_DEfeatures)[3], ylab = 'Prediction using Logistic Reg.')

writeLines("\nNot bad!  Of our 28 samples, only  2 were misclassified as cure when they were actually failure in the first model, and 3 misclassified in the 2nd and 3rd. My guess is we would rather false negatives (were actually cure when we predict they would be failure to cure). Is this correct?")


corrs <- cor(train_DEfeatures[,1:3])
corrplot(corrs, method="color")

writeLines("/nThey're all pretty highly correlated and redundant. Let's do stepwise regression to make sure it agrees that these are redundant.")
```


## Backard Stepwise Regression
```{r}
#full model
fit_full <- glm(target_train_binary ~ ENSG00000282278 + ENSG00000273734 + ENSG00000266086 + ENSG00000268797, family=binomial, data= train_DEfeatures)

#backward stepwise regression (suppressing output with trace = 0)
backwards <- step(fit_full, trace = 0) 

writeLines("The optimal model using backward stepwise regression with the first top 4 DE genes is:\n")
formula(backwards)

writeLines("\nwith AIC = ")
backwards$aic
```


## Forward Stepwise Regression
```{r}
fit_0 <- glm(target_train_binary ~ 1, family=binomial, data = train_DEfeatures)
forwards = step(fit_0, scope=list(lower=formula(fit_0), upper=formula(fit_full)), direction="forward", trace = 0)

writeLines("The optimal model using backward stepwise regression with the first top 4 DE genes is: \n")
formula(forwards)

writeLines("\nwith AIC = ")
forwards$aic

writeLines("\nSo the forwards and backwards stepwise models agree that of the top 4 DE genes, ENSG00000204577 + ENSG00000282278 should be included in the model.")
```


## Stepwise Both directions
```{r}
bothways <- step(fit_0, list(lower=formula(fit_0), upper=formula(fit_full)), direction="both", trace=0)

writeLines("The formula using both ways stepwise regression finds the same model as well: \n ")
formula(bothways)

writeLines("\nwith AIC = ")
bothways$aic
```

## Just for fun... picking 4 random genes from top 25 gene lines
```{r}
set.seed(11)
randomgenes <- sample(1:25, 4)

randomgenessubset <- as.data.frame(train_DEfeatures[,randomgenes])

fit_random <- glm(target_train_binary ~ randomgenessubset[,1] + randomgenessubset[,2] + randomgenessubset[,3] + randomgenessubset[,4], family=binomial, data= randomgenessubset)

#backward stepwise regression (suppressing output with trace = 0)
random <- step(fit_random, trace = 0) 

writeLines("The optimal model using random 4 genes and backwards stepwise regression is:\n")
formula(random)

writeLines("\nwith AIC = ")
random$aic

writeLines("So even with a random set of 4 genes from the top DE gene list, the AIC is comparable (and even a little bit better!), meaning the model is still pretty comparable. So are the top DE genes really helping us make a better model or would any random subset of the top DE genes do just as well?")

```

## Let's bootstrap that to see disctribution of AICs for models with random subsets of genes

I created an AIC value for 100 random draws of 3 genes from the top 25 gene's list. This will tell us if what we got from the above models (with an AIC value of ~36) generally performs 
```{r, warning=FALSE}
AICs <- c()
models <- data.frame(row.names = c("gene1", "gene2", "gene3", "gene4"))
for (i in 1:100){
  randomgenes <- sample(1:25, 4)
  randomgenessubset <- as.data.frame(train_DEfeatures[,randomgenes])
  fit_random <- glm(target_train_binary ~ randomgenessubset[,1] + randomgenessubset[,2] + randomgenessubset[,3],
                    family=binomial, 
                    data= randomgenessubset)
  #backward stepwise regression (suppressing output with trace = 0)
  random <- step(fit_random, trace = 0) 
  models <- cbind(models, randomgenes)
  AICs <- c(AICs, random$aic)
}

d <- density(AICs)
plot(d, main="Kernel Density of bootstrapped AICs")
polygon(d, col="red", border="red")


writeLines(paste("Hmmm, so this isn't great. This is showing us that if we take random subsets of genes from the top 25 genes, the mean AIC for those models is", round(mean(AICs),2), ", so our models using only the top 3 DE genes really isn't doing any better than a model taking a random subset of 3 genes in the top 25 DE genes. Let's check how highly correlated our top DE genes are. If the top DE genes are highly correlated across samples, this may tell us why our model is only as good as the mean of 100 randomly generated models"))

```

## Correlation between top 25 DE gene's expression profiles across all samples
```{r}
library(corrplot)
correlations <- cor(train_DEfeatures[,1:25])
corrplot(correlations, method="color")


writeLines("We see a lot of highly correlated gene pairs in the top 25 DE genes, so I guess our model's AIC score is not that surprising since there is a high change that 3 randomly chosen genes have some correlation to the 3 top DE genes we made our initial model with. I think this is overall good news because we may have many gene candidates that end up being good predictors to choose from for a potential assay.")
```



# LDA for informative feature selection
## Do LDA on top DE features 
```{r}
library(MASS)
#train LDA classifier
train_LDA <- lda(train_DEfeatures, target_train)

LDApredictions <- predict(train_LDA, train_DEfeatures)
LDApredictions_df <- data.frame(LDAweights = LDApredictions$x, Prediction = LDApredictions$class, True = as.factor(target_train))

#extract genes which have the highest magnitude weights (similar to if you were going to look at the weights of the PC's)
topLDA_features <- head(train_LDA$scaling[order(abs(train_LDA$scaling), decreasing = TRUE),], 11)

plot(abs(train_LDA$scaling[order(abs(train_LDA$scaling), decreasing = TRUE),]), ylab = "Magnitude of LD Weights", main = "Magnitude of LD Weights for Each Gene")
abline(v = 11.5)


writeLines("This gives us an indication of which genes are important in helping to separate the cures from the fail to cures, Each point is the weight given to a gene in how 'important' or discfriminatory that gene is in the LDA embedding. You could think of this kind of as an elbow plot that you might use to determine how many PC's to use which captures a majority of the variation. From this plot, I would say we should look at the top 11 genes here, which is where the weights start to level off.")
```


```{r}

#pull out expression data for these top genes
LDAgenessubset <- as.data.frame(train_DEfeatures[,names(topLDA_features)])


#logit model using these genes 
fit_LDAvars <- glm(target_train_binary ~ ENSG00000281039 + ENSG00000259371 + ENSG00000268797 + ENSG00000282804 + ENSG00000272410 + ENSG00000283977 + ENSG00000173366 + ENSG00000266086, family=binomial, data= LDAgenessubset)


#backward stepwise regression (suppressing output with trace = 0)
LDAfit <- step(fit_LDAvars, trace = 0) 

writeLines("The optimal model using the top 6 genes from the LDA weights and backwards stepwise regression is:\n")
formula(LDAfit)

writeLines("\nwith AIC = ")
LDAfit$aic


writeLines(paste("\nThese two genes are numbers", which(top25DEgenes_down == "ENSG00000259371"), ",", which(top25DEgenes_down == "ENSG00000272410"), "and", which(top25DEgenes_down == "ENSG00000173366"), "in the DE gene order."))


writeLines("\nSo using the top LDA genes to build a logit model is a bit better than what we got using the just the top DE genes and is better than the mean AIC of the random subset of top DE genes. So far, this method of feature selection is the most optimal.")
```

## Let's look at what using the LDA classifier gives us
```{r}
library(plotly)
topLDA_features

plot(train_LDA)
writeLines("/nThe LDA model is 100% accurate in the predictions of pass/fail (although this is kind of obvious since we used the same samples to make predictions as we did to build the model, although I did the same for the logit model and we still didn't get 100% accuracy.
           ) ")
#ggplot(LDApredictions_df, aes(x = LD1, y = train_DEfeatures[,"ENSG00000281039"], col = Prediction)) + geom_point() + ylab("ENSG00000281039 Expression") + ggtitle("Top Weighted LD Gene")

#ggplot(LDApredictions_df, aes(x = LD1, y = train_DEfeatures[,"ENSG00000259371"], col = Prediction)) + geom_point() + ylab("ENSG00000259371 Expression") + ggtitle("Top Weighted LD Gene")

#ggplot(LDApredictions_df, aes(x = LD1, y = train_DEfeatures[,"ENSG00000268797"], col = Prediction)) + geom_point() + ylab("ENSG00000268797 Expression") + ggtitle("Top Weighted LD Gene")


fig <- plot_ly(LDApredictions_df, x = ~train_DEfeatures[,"ENSG00000259371"], y = ~train_DEfeatures[,"ENSG00000281039"], z = ~train_DEfeatures[,"ENSG00000268797"], color = ~True, colors = c('#BF382A', '#0C4B8E'))
fig <- fig %>% add_markers()
fig <- fig %>% layout(scene = list(xaxis = list(title = "ENSG00000259371"),
                     yaxis = list(title = "ENSG00000281039"),
                     zaxis = list(title = "ENSG00000268797")))

fig

writeLines("These are the first 3 top weighted LD genes. We can see they do a pretty good job of separating out ")
```




# Let's try an SVM

```{r, include = FALSE}
library(e1071)
library(caret)

DEdat = data.frame(LDAgenessubset[,1:2], y = as.factor(target_train))
svmfit = svm(y ~ ., data = DEdat, kernel = "polynomial", cost = 50, scale = FALSE)
plot(svmfit, DEdat)
```



